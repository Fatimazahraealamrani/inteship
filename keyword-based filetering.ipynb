{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now the user can enter on ù or more keyword for researsh , so now i will trait this with the similarity beetween the words and the tapping word .\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27555 entries, 0 to 27554\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   index         27555 non-null  int64  \n",
      " 1   product       27554 non-null  object \n",
      " 2   category      27555 non-null  object \n",
      " 3   sub_category  27555 non-null  object \n",
      " 4   brand         27554 non-null  object \n",
      " 5   sale_price    27555 non-null  float64\n",
      " 6   market_price  27555 non-null  float64\n",
      " 7   type          27555 non-null  object \n",
      " 8   rating        18929 non-null  float64\n",
      " 9   description   27440 non-null  object \n",
      "dtypes: float64(3), int64(1), object(6)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#to convert the text data into TF-IDF vectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#to convert the text data into TF-IDF vectors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data2=pd.read_csv('ALL_PRODUCTS.csv')\n",
    "data2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The TF-IDF vectorizer converts the text data into numerical vectors using the TF-IDF formula. It calculates the Term Frequency (TF) for each term (word)\\ncalcul un pourcentage dans le mot inferieu a 1 \\nexample pour mieux comprendre:\\ndocuments = [\\n    \"This is the first document.\",\\n    \"This is the second document.\",\\n    \"And this is the third one.\",\\n    \"Is this the first document?\",\\n]\\n\\n\\n       and          document.    first       is          one         second       the          third       this\\n\\n0      0.000000     0.332742     0.332742    0.332742    0.000000    0.000000     0.000000     0.332742\\n\\n1      0.000000     0.332742     0.000000    0.332742    0.000000    0.472120     0.000000     0.332742\\n\\n2      0.521719     0.000000     0.000000    0.000000    0.521719    0.000000     0.521719     0.000000\\n\\n3      0.000000     0.332742     0.332742    0.332742    0.000000    0.000000     0.000000     0.332742\\n\\nthis is the output donc , on voit le pourcentage d\\'apparence de chaque mot dans la phrase ,so we have now a matrix ,\\n than can be compared with another one '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''The TF-IDF vectorizer converts the text data into numerical vectors using the TF-IDF formula. It calculates the Term Frequency (TF) for each term (word)\n",
    "calcul un pourcentage dans le mot inferieu a 1 \n",
    "example pour mieux comprendre:\n",
    "documents = [\n",
    "    \"This is the first document.\",\n",
    "    \"This is the second document.\",\n",
    "    \"And this is the third one.\",\n",
    "    \"Is this the first document?\",\n",
    "]\n",
    "\n",
    "\n",
    "       and          document.    first       is          one         second       the          third       this\n",
    "\n",
    "0      0.000000     0.332742     0.332742    0.332742    0.000000    0.000000     0.000000     0.332742\n",
    "\n",
    "1      0.000000     0.332742     0.000000    0.332742    0.000000    0.472120     0.000000     0.332742\n",
    "\n",
    "2      0.521719     0.000000     0.000000    0.000000    0.521719    0.000000     0.521719     0.000000\n",
    "\n",
    "3      0.000000     0.332742     0.332742    0.332742    0.000000    0.000000     0.000000     0.332742\n",
    "\n",
    "this is the output donc , on voit le pourcentage d'apparence de chaque mot dans la phrase ,so we have now a matrix ,\n",
    " than can be compared with another one '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1-We use a special tool called the TfidfVectorizer to transform the product descriptions (text data) into numbers,\\n making it easier for the computer to understand and analyze them. This transformation uses the TF-IDF method, \\nwhich helps us figure out how important each word is in a description compared to all the descriptions in the dataset.\\n\\n2-The cosine_similarity function is then used to compare the input text (a product's description) with the \\ndescriptions of all the other products in the dataset. It calculates a measure of similarity based on the direction\\n and angle between the numerical representations of the descriptions.\\n\\n3-Lastly, the recommend_product function utilizes the results from the cosine_similarity calculations. \\nIt finds the product in the dataset that has the highest similarity to the input text (product description).\\n This way, we can identify the most similar product and present its details as a recommendation for the input product description.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''1-We use a special tool called the TfidfVectorizer to transform the product descriptions (text data) into numbers,\n",
    " making it easier for the computer to understand and analyze them. This transformation uses the TF-IDF method, \n",
    "which helps us figure out how important each word is in a description compared to all the descriptions in the dataset.\n",
    "\n",
    "2-The cosine_similarity function is then used to compare the input text (a product's description) with the \n",
    "descriptions of all the other products in the dataset. It calculates a measure of similarity based on the direction\n",
    " and angle between the numerical representations of the descriptions.\n",
    "\n",
    "3-Lastly, the recommend_product function utilizes the results from the cosine_similarity calculations. \n",
    "It finds the product in the dataset that has the highest similarity to the input text (product description).\n",
    " This way, we can identify the most similar product and present its details as a recommendation for the input product description.'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer= TfidfVectorizer(stop_words='english')\n",
    "#Stop words are common words in a language that are typically filtered\n",
    "#out or ignored when processing natural language text\n",
    "# Examples of stop words in English include \"the,\" \"and,\" \"in,\" \"to,\" \"is,\" \"at,\" \"it,\" and so on.\n",
    "\n",
    "tfidf_matrix= vectorizer.fit_transform(data2['description'].values.astype('U'))\n",
    "# 'astype('U')' permet de convertir les données textuelles en Unicode pour éviter tout problème d'encodage.\n",
    "\n",
    "def recommend_product(input_text):\n",
    "    input_vector= vectorizer.transform([input_text])\n",
    "    # transforming the user entered query into vectors using TF-IDF\n",
    "    similarities=cosine_similarity(input_vector,tfidf_matrix)\n",
    "\n",
    "    most_similar_index=similarities.argmax()\n",
    "    most_similar_product=data2.iloc[most_similar_index]\n",
    "    return most_similar_product\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_user=input (\"entrer votre descirption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Product:\n",
      "ligne: 126\n",
      "Name: Premium Square Plastic Container - Green\n",
      "Brand: Mastercook\n",
      "Category: Kitchen, Garden & Pets\n"
     ]
    }
   ],
   "source": [
    "recommended_product = recommend_product(input_user)\n",
    "if recommended_product is not None:\n",
    "    print(\"Recommended Product:\")\n",
    "    print(\"ligne:\", recommended_product['index'])\n",
    "\n",
    "    print(\"Name:\", recommended_product['product'])\n",
    "    print(\"Brand:\", recommended_product['brand'])\n",
    "    print(\"Category:\", recommended_product['category'])\n",
    "\n",
    "else:\n",
    "    print(\"No recommended product found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so now we have the most similar result of what the user firstyly taped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we searsh to see more than 1 result , for example 5\n",
    "\n",
    "def recommend_product(input_text,nbr_recommendation=5):\n",
    "    input_vector=vectorizer.transform([input_text])\n",
    "    similarities=cosine_similarity(input_vector,tfidf_matrix)\n",
    "\n",
    "    #now we get the indices of the top N most similar products\n",
    "    #the argsort fucntion used to get the indices of the top products\n",
    "\n",
    "\n",
    "    top_indices =similarities.argsort()[0][-nbr_recommendation:][::1]\n",
    "    #on va obtenir un vecteur car on a etudier la similarite entre la matrice et le vecteur \n",
    "    #donc apres l'operation sort on va prendre les 5 derniers et les inverser\n",
    "\n",
    "    top_products=data2.iloc[top_indices]\n",
    "    return top_products\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input=input('donner votre dtext :')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nbr 24336\n",
      "name: Whey Protein - Cafe Mocha\n",
      "Name: Whey Protein - Cafe Mocha\n",
      "Brand: IN2\n",
      "Category: Beauty & Hygiene\n",
      "-----------------------------\n",
      "nbr 3005\n",
      "name: Prince Pilot Plastic Container Set - Pink\n",
      "Name: Prince Pilot Plastic Container Set - Pink\n",
      "Brand: Princeware\n",
      "Category: Kitchen, Garden & Pets\n",
      "-----------------------------\n",
      "nbr 12728\n",
      "name: Prince Pilot Plastic Container Set - Blue\n",
      "Name: Prince Pilot Plastic Container Set - Blue\n",
      "Brand: Princeware\n",
      "Category: Kitchen, Garden & Pets\n",
      "-----------------------------\n",
      "nbr 4241\n",
      "name: Weikfield White Oats\n",
      "Name: Weikfield White Oats\n",
      "Brand: Eco Valley \n",
      "Category: Snacks & Branded Foods\n",
      "-----------------------------\n",
      "nbr 21459\n",
      "name: Protein Muesli - Chocolate Flavoured\n",
      "Name: Protein Muesli - Chocolate Flavoured\n",
      "Brand: Bagrrys\n",
      "Category: Snacks & Branded Foods\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "recommended_product=recommend_product(user_input,5)\n",
    "\n",
    "for ind,product in recommended_product.iterrows():\n",
    "     print(\"nbr\",product['index'])\n",
    "     \n",
    "     print(\"name:\",product['product'])\n",
    "     print(\"Name:\", product['product'])\n",
    "     print(\"Brand:\", product['brand'])\n",
    "     print(\"Category:\", product['category'])\n",
    "     print(\"-----------------------------\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
